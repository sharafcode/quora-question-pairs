{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OonS96or84-"
      },
      "source": [
        "# Data Loading "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BPts5ORbhUl",
        "outputId": "3aed910c-f57c-46e1-a5c9-589c9c3062e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_he0uiIwVy3s",
        "outputId": "1b25c9b5-f522-480c-b9cf-4d53347ef81d"
      },
      "source": [
        "% pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 44.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 60.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=8b1a616a1ee8cd86c729f660125d7ea0fecb5739814d984c05531934a0add3fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 sentence-transformers-2.0.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvnbSG2dsvG5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score , cohen_kappa_score\n",
        "import gensim\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jXnr9lLsE31"
      },
      "source": [
        "train_df= pd.read_csv(\"/content/drive/MyDrive/DEBI/Ottawa/Data Science Applications/Assignments/Group_project/final_project/Dataset/train.csv\")\n",
        "test_df= pd.read_csv(\"/content/drive/MyDrive/DEBI/Ottawa/Data Science Applications/Assignments/Group_project/final_project/Dataset/test.csv\")\n",
        "test_labels_df= pd.read_csv(\"/content/drive/MyDrive/DEBI/Ottawa/Data Science Applications/Assignments/Group_project/final_project/Dataset/sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vj4V9iAL7jE"
      },
      "source": [
        "train_df= pd.read_csv(\"/content/drive/MyDrive/Group_project/final_project/Dataset/training_data_cleaned.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KWXL9wpt2xb",
        "outputId": "df6c5466-6afa-4c7d-f8c7-3a4e504eb96e"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXz_NjH10lf"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cFgW13L13vL"
      },
      "source": [
        "##Elbow method for clustering\n",
        "def optimum_k(max_k,X):\n",
        "  wcss = []\n",
        "  for i in range(2, max_k):\n",
        "    #kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans =MiniBatchKMeans(n_clusters=i, init='k-means++', n_init=1, init_size=1000, batch_size=1000, verbose=False, max_iter=1000)\n",
        "    cluster_labels=kmeans.fit(X)\n",
        "    print(\"model finished training\")\n",
        "    silhouette_avg = silhouette_score(X, kmeans.fit_predict(X))\n",
        "    print(\"For n_clusters =\", i,\n",
        "          \"The average silhouette_score is :\", silhouette_avg)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "  plt.plot(range(2, max_k), wcss)\n",
        "  plt.title('Elbow Method')\n",
        "  plt.xlabel('Number of clusters')\n",
        "  plt.ylabel('WCSS')\n",
        "  plt.show()\n",
        "#return wcss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3CaJNeqtCVk"
      },
      "source": [
        "##getting length of each question\n",
        "def ques_len(train_df):\n",
        "    q=train_df.split(\" \")\n",
        "    return len(q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AbarKW4ztQG"
      },
      "source": [
        "def read_questions(row,column_name):\n",
        "    return gensim.utils.simple_preprocess(str(row[column_name]).encode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qMgw7hq2bGH"
      },
      "source": [
        "##Getting the avergae vector of the all the word embeddings in a sentence\n",
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "    \n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
        "    nwords = 0.\n",
        "    \n",
        "    for word in words:\n",
        "        if word in vocabulary: \n",
        "            nwords = nwords + 1.\n",
        "            feature_vector = np.add(feature_vector, model[word])\n",
        "    \n",
        "    if nwords:\n",
        "        feature_vector = np.divide(feature_vector, nwords)\n",
        "        \n",
        "    return feature_vector\n",
        "\n",
        "   \n",
        "def averaged_word_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A2t--q54xo1"
      },
      "source": [
        "# Method contains all the classification algorithms\n",
        "def estimators(features, labels, estimator):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "     features, labels, test_size=0.2, random_state=0)\n",
        "  if (estimator == 'SVM'):\n",
        "    model = svm.SVC().fit(X_train, y_train )\n",
        "    text = 'SVM'\n",
        "  if (estimator == 'DecisionTree'):\n",
        "    model = DecisionTreeClassifier(max_depth=10).fit(X_train, y_train)\n",
        "    text = 'Decision Tree'\n",
        "  if (estimator == 'KNN'):\n",
        "    model = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)\n",
        "    text = 'KNN'\n",
        "  if (estimator == 'RandomForest'):\n",
        "    text = 'RandomForest'\n",
        "    model=RandomForestClassifier(max_depth=15, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "  train_prediction = model.predict(X_train)\n",
        "  prediction = model.predict(X_test)\n",
        "  print(text, \" Train Accuracy : \", accuracy_score(y_train,train_prediction)*100)\n",
        "  print(text, \" Test Accuracy : \", accuracy_score(y_test,prediction)*100)\n",
        "  print(\"\\n\\t\\tTEST DATA METRICS\")\n",
        "  print(text, \" Confusion Matrix: \",confusion_matrix(y_test, prediction))\n",
        "  print(text, \" Report : \")\n",
        "  print(classification_report(y_test,prediction))  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3X2Rs2HwC1U"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1HBkczMeHe_"
      },
      "source": [
        "Word2VEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpAHSgXMz_UR"
      },
      "source": [
        "##Getting all unique questions in the dataset\n",
        "all_questions=pd.concat([train_df['question1'] , train_df['question2']],axis=0, ignore_index=True)\n",
        "all_questions=all_questions.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCkz7sGo0hWa"
      },
      "source": [
        "##Transform all the training questions\n",
        "documents=[]\n",
        "for q in all_questions:\n",
        "    documents.append(gensim.utils.simple_preprocess(str(q).encode('utf-8')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE0DlQsvsaYy",
        "outputId": "18dda259-2e83-485c-fc81-478d18b731be"
      },
      "source": [
        "len(documents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "536013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDX174swhCBd"
      },
      "source": [
        "###Buiding the Word2vec model\n",
        "model = gensim.models.Word2Vec(size=300, window=10, min_count=10, sg=1, workers=10)\n",
        "model.build_vocab(documents)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1QmmeSAhVr3",
        "outputId": "77a68e00-44f8-474a-fa58-dd97533c5f44"
      },
      "source": [
        "###Training the Word2vec model\n",
        "model.train(sentences=documents, total_examples=len(documents), epochs=model.iter)\n",
        "model.corpus_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "536013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr7YsxuCv-tB"
      },
      "source": [
        "##Transform the 2 questions in the train dataframe\n",
        "q1 = []\n",
        "q2=[]\n",
        "for index, row in train_df.iterrows():\n",
        "    q1.append(read_questions(row,\"question1\"))\n",
        "    q2.append(read_questions(row,\"question2\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "X-wKBjmzvrfu",
        "outputId": "0e0df513-9b45-49f1-f2d2-1ba5324715ab"
      },
      "source": [
        "###Gettinhg the feature vector of the first question\n",
        "w2v_q1 = averaged_word_vectorizer(corpus=q1, model=model,num_features=300)\n",
        "w2v_q1=pd.DataFrame(w2v_q1)\n",
        "w2v_q1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.002163</td>\n",
              "      <td>0.035122</td>\n",
              "      <td>0.035819</td>\n",
              "      <td>0.080290</td>\n",
              "      <td>-0.127455</td>\n",
              "      <td>-0.195097</td>\n",
              "      <td>0.129632</td>\n",
              "      <td>0.012980</td>\n",
              "      <td>0.017270</td>\n",
              "      <td>-0.139771</td>\n",
              "      <td>-0.052276</td>\n",
              "      <td>-0.015170</td>\n",
              "      <td>0.026436</td>\n",
              "      <td>-0.046106</td>\n",
              "      <td>0.014357</td>\n",
              "      <td>-0.172406</td>\n",
              "      <td>0.172847</td>\n",
              "      <td>-0.031739</td>\n",
              "      <td>0.024736</td>\n",
              "      <td>-0.036092</td>\n",
              "      <td>-0.251780</td>\n",
              "      <td>-0.137283</td>\n",
              "      <td>0.043327</td>\n",
              "      <td>0.209316</td>\n",
              "      <td>-0.090279</td>\n",
              "      <td>-0.094340</td>\n",
              "      <td>0.037664</td>\n",
              "      <td>-0.020217</td>\n",
              "      <td>0.094674</td>\n",
              "      <td>-0.140906</td>\n",
              "      <td>-0.147094</td>\n",
              "      <td>-0.059406</td>\n",
              "      <td>-0.145525</td>\n",
              "      <td>0.069240</td>\n",
              "      <td>0.106495</td>\n",
              "      <td>-0.192783</td>\n",
              "      <td>0.180365</td>\n",
              "      <td>0.007296</td>\n",
              "      <td>0.043680</td>\n",
              "      <td>0.102318</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136424</td>\n",
              "      <td>0.056346</td>\n",
              "      <td>0.070465</td>\n",
              "      <td>-0.074184</td>\n",
              "      <td>-0.078636</td>\n",
              "      <td>0.013977</td>\n",
              "      <td>-0.053577</td>\n",
              "      <td>0.084379</td>\n",
              "      <td>0.098539</td>\n",
              "      <td>0.020164</td>\n",
              "      <td>0.010111</td>\n",
              "      <td>-0.003979</td>\n",
              "      <td>-0.021690</td>\n",
              "      <td>0.025680</td>\n",
              "      <td>-0.037753</td>\n",
              "      <td>0.181907</td>\n",
              "      <td>-0.058441</td>\n",
              "      <td>-0.028937</td>\n",
              "      <td>0.120210</td>\n",
              "      <td>0.031621</td>\n",
              "      <td>0.038254</td>\n",
              "      <td>0.038463</td>\n",
              "      <td>0.020142</td>\n",
              "      <td>-0.096275</td>\n",
              "      <td>0.140266</td>\n",
              "      <td>0.077175</td>\n",
              "      <td>-0.040723</td>\n",
              "      <td>0.075920</td>\n",
              "      <td>-0.190359</td>\n",
              "      <td>-0.019146</td>\n",
              "      <td>-0.062460</td>\n",
              "      <td>0.109519</td>\n",
              "      <td>-0.057846</td>\n",
              "      <td>0.008718</td>\n",
              "      <td>-0.057391</td>\n",
              "      <td>0.073275</td>\n",
              "      <td>-0.044224</td>\n",
              "      <td>0.080690</td>\n",
              "      <td>0.018476</td>\n",
              "      <td>0.099836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.125517</td>\n",
              "      <td>0.040885</td>\n",
              "      <td>0.002634</td>\n",
              "      <td>0.027717</td>\n",
              "      <td>-0.097512</td>\n",
              "      <td>-0.260680</td>\n",
              "      <td>0.061009</td>\n",
              "      <td>0.051703</td>\n",
              "      <td>0.035252</td>\n",
              "      <td>-0.122280</td>\n",
              "      <td>0.003330</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>0.020666</td>\n",
              "      <td>-0.048231</td>\n",
              "      <td>-0.055681</td>\n",
              "      <td>-0.075096</td>\n",
              "      <td>0.075293</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.061264</td>\n",
              "      <td>-0.103155</td>\n",
              "      <td>-0.221954</td>\n",
              "      <td>-0.045125</td>\n",
              "      <td>-0.069526</td>\n",
              "      <td>0.176508</td>\n",
              "      <td>-0.091669</td>\n",
              "      <td>0.020900</td>\n",
              "      <td>-0.020063</td>\n",
              "      <td>0.043110</td>\n",
              "      <td>0.095051</td>\n",
              "      <td>-0.177319</td>\n",
              "      <td>-0.106537</td>\n",
              "      <td>-0.044107</td>\n",
              "      <td>0.031159</td>\n",
              "      <td>0.107986</td>\n",
              "      <td>0.164050</td>\n",
              "      <td>-0.200838</td>\n",
              "      <td>0.181508</td>\n",
              "      <td>0.093262</td>\n",
              "      <td>-0.009593</td>\n",
              "      <td>0.073111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057935</td>\n",
              "      <td>0.059165</td>\n",
              "      <td>0.006636</td>\n",
              "      <td>-0.037180</td>\n",
              "      <td>-0.087129</td>\n",
              "      <td>-0.037673</td>\n",
              "      <td>-0.083051</td>\n",
              "      <td>0.055666</td>\n",
              "      <td>0.016815</td>\n",
              "      <td>0.002815</td>\n",
              "      <td>0.128640</td>\n",
              "      <td>-0.002452</td>\n",
              "      <td>0.027006</td>\n",
              "      <td>-0.017187</td>\n",
              "      <td>-0.062249</td>\n",
              "      <td>0.040854</td>\n",
              "      <td>0.008765</td>\n",
              "      <td>-0.103796</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.122168</td>\n",
              "      <td>0.130311</td>\n",
              "      <td>-0.064587</td>\n",
              "      <td>-0.030344</td>\n",
              "      <td>-0.120849</td>\n",
              "      <td>0.135307</td>\n",
              "      <td>-0.003176</td>\n",
              "      <td>0.019094</td>\n",
              "      <td>0.039309</td>\n",
              "      <td>-0.173098</td>\n",
              "      <td>-0.004068</td>\n",
              "      <td>0.064552</td>\n",
              "      <td>0.092786</td>\n",
              "      <td>-0.074986</td>\n",
              "      <td>-0.092073</td>\n",
              "      <td>0.124897</td>\n",
              "      <td>0.121293</td>\n",
              "      <td>-0.071283</td>\n",
              "      <td>0.113860</td>\n",
              "      <td>0.037437</td>\n",
              "      <td>-0.029801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.027636</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>0.084629</td>\n",
              "      <td>-0.170868</td>\n",
              "      <td>-0.072945</td>\n",
              "      <td>0.191756</td>\n",
              "      <td>0.128479</td>\n",
              "      <td>-0.116690</td>\n",
              "      <td>0.128140</td>\n",
              "      <td>-0.051011</td>\n",
              "      <td>-0.092370</td>\n",
              "      <td>-0.020107</td>\n",
              "      <td>-0.152984</td>\n",
              "      <td>0.204748</td>\n",
              "      <td>-0.161526</td>\n",
              "      <td>0.049819</td>\n",
              "      <td>0.019887</td>\n",
              "      <td>0.122460</td>\n",
              "      <td>-0.155580</td>\n",
              "      <td>-0.184943</td>\n",
              "      <td>0.022622</td>\n",
              "      <td>0.092670</td>\n",
              "      <td>0.201726</td>\n",
              "      <td>-0.046593</td>\n",
              "      <td>-0.041185</td>\n",
              "      <td>0.025331</td>\n",
              "      <td>0.167134</td>\n",
              "      <td>0.078739</td>\n",
              "      <td>-0.098673</td>\n",
              "      <td>-0.176630</td>\n",
              "      <td>-0.158972</td>\n",
              "      <td>-0.013273</td>\n",
              "      <td>0.165712</td>\n",
              "      <td>0.152212</td>\n",
              "      <td>-0.132907</td>\n",
              "      <td>0.136436</td>\n",
              "      <td>0.181070</td>\n",
              "      <td>0.153263</td>\n",
              "      <td>0.075403</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.064265</td>\n",
              "      <td>-0.144807</td>\n",
              "      <td>0.009674</td>\n",
              "      <td>0.004838</td>\n",
              "      <td>-0.054514</td>\n",
              "      <td>-0.033621</td>\n",
              "      <td>0.053500</td>\n",
              "      <td>-0.092143</td>\n",
              "      <td>-0.126329</td>\n",
              "      <td>0.023916</td>\n",
              "      <td>0.044758</td>\n",
              "      <td>0.025657</td>\n",
              "      <td>-0.109099</td>\n",
              "      <td>0.067679</td>\n",
              "      <td>0.137411</td>\n",
              "      <td>-0.046691</td>\n",
              "      <td>0.033492</td>\n",
              "      <td>-0.016260</td>\n",
              "      <td>0.031983</td>\n",
              "      <td>0.020691</td>\n",
              "      <td>-0.067457</td>\n",
              "      <td>-0.018843</td>\n",
              "      <td>-0.202349</td>\n",
              "      <td>0.176044</td>\n",
              "      <td>0.069759</td>\n",
              "      <td>0.086411</td>\n",
              "      <td>0.040028</td>\n",
              "      <td>-0.098950</td>\n",
              "      <td>-0.083675</td>\n",
              "      <td>-0.041226</td>\n",
              "      <td>0.009160</td>\n",
              "      <td>-0.094366</td>\n",
              "      <td>0.173614</td>\n",
              "      <td>-0.050696</td>\n",
              "      <td>0.009985</td>\n",
              "      <td>-0.144106</td>\n",
              "      <td>0.152622</td>\n",
              "      <td>-0.059203</td>\n",
              "      <td>0.070782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.030151</td>\n",
              "      <td>-0.052437</td>\n",
              "      <td>-0.072858</td>\n",
              "      <td>-0.033903</td>\n",
              "      <td>-0.241715</td>\n",
              "      <td>-0.245293</td>\n",
              "      <td>-0.017979</td>\n",
              "      <td>0.056697</td>\n",
              "      <td>-0.055551</td>\n",
              "      <td>-0.028526</td>\n",
              "      <td>-0.038385</td>\n",
              "      <td>-0.161696</td>\n",
              "      <td>-0.055732</td>\n",
              "      <td>-0.200679</td>\n",
              "      <td>0.139876</td>\n",
              "      <td>-0.104797</td>\n",
              "      <td>0.010157</td>\n",
              "      <td>0.030354</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>-0.120482</td>\n",
              "      <td>-0.089914</td>\n",
              "      <td>-0.006215</td>\n",
              "      <td>0.037878</td>\n",
              "      <td>0.259407</td>\n",
              "      <td>-0.258481</td>\n",
              "      <td>-0.063186</td>\n",
              "      <td>0.081307</td>\n",
              "      <td>0.105329</td>\n",
              "      <td>0.018137</td>\n",
              "      <td>0.010288</td>\n",
              "      <td>-0.128425</td>\n",
              "      <td>-0.280407</td>\n",
              "      <td>-0.145920</td>\n",
              "      <td>0.027172</td>\n",
              "      <td>0.069344</td>\n",
              "      <td>-0.054411</td>\n",
              "      <td>0.193812</td>\n",
              "      <td>0.054636</td>\n",
              "      <td>0.028974</td>\n",
              "      <td>0.150698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.145036</td>\n",
              "      <td>0.030045</td>\n",
              "      <td>-0.092498</td>\n",
              "      <td>0.196459</td>\n",
              "      <td>-0.302595</td>\n",
              "      <td>-0.084082</td>\n",
              "      <td>-0.046537</td>\n",
              "      <td>0.093960</td>\n",
              "      <td>0.009082</td>\n",
              "      <td>-0.044578</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.031871</td>\n",
              "      <td>0.099935</td>\n",
              "      <td>-0.126385</td>\n",
              "      <td>0.083117</td>\n",
              "      <td>0.090465</td>\n",
              "      <td>-0.090463</td>\n",
              "      <td>0.036027</td>\n",
              "      <td>-0.010596</td>\n",
              "      <td>-0.013625</td>\n",
              "      <td>-0.084403</td>\n",
              "      <td>0.028801</td>\n",
              "      <td>-0.103475</td>\n",
              "      <td>-0.160023</td>\n",
              "      <td>0.288690</td>\n",
              "      <td>-0.115082</td>\n",
              "      <td>0.062536</td>\n",
              "      <td>-0.078020</td>\n",
              "      <td>-0.189327</td>\n",
              "      <td>-0.063849</td>\n",
              "      <td>-0.124212</td>\n",
              "      <td>0.037154</td>\n",
              "      <td>-0.136418</td>\n",
              "      <td>0.081586</td>\n",
              "      <td>0.022412</td>\n",
              "      <td>0.044791</td>\n",
              "      <td>-0.109677</td>\n",
              "      <td>0.013263</td>\n",
              "      <td>-0.008422</td>\n",
              "      <td>0.044738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.093965</td>\n",
              "      <td>0.158807</td>\n",
              "      <td>-0.077798</td>\n",
              "      <td>0.110590</td>\n",
              "      <td>-0.137603</td>\n",
              "      <td>-0.133700</td>\n",
              "      <td>-0.061604</td>\n",
              "      <td>0.128639</td>\n",
              "      <td>0.159119</td>\n",
              "      <td>-0.007342</td>\n",
              "      <td>0.089216</td>\n",
              "      <td>-0.031685</td>\n",
              "      <td>-0.079609</td>\n",
              "      <td>-0.119939</td>\n",
              "      <td>0.061430</td>\n",
              "      <td>-0.210301</td>\n",
              "      <td>-0.147206</td>\n",
              "      <td>0.027828</td>\n",
              "      <td>0.176474</td>\n",
              "      <td>-0.169055</td>\n",
              "      <td>-0.200878</td>\n",
              "      <td>0.025314</td>\n",
              "      <td>0.085715</td>\n",
              "      <td>0.066942</td>\n",
              "      <td>-0.156084</td>\n",
              "      <td>0.129519</td>\n",
              "      <td>-0.079695</td>\n",
              "      <td>-0.015821</td>\n",
              "      <td>0.046214</td>\n",
              "      <td>0.013741</td>\n",
              "      <td>-0.044095</td>\n",
              "      <td>-0.090653</td>\n",
              "      <td>0.058446</td>\n",
              "      <td>0.094161</td>\n",
              "      <td>0.202813</td>\n",
              "      <td>-0.174566</td>\n",
              "      <td>0.235988</td>\n",
              "      <td>-0.014625</td>\n",
              "      <td>0.196560</td>\n",
              "      <td>0.081944</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030017</td>\n",
              "      <td>-0.110213</td>\n",
              "      <td>-0.088019</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>-0.162359</td>\n",
              "      <td>0.050232</td>\n",
              "      <td>-0.079966</td>\n",
              "      <td>0.063440</td>\n",
              "      <td>0.029063</td>\n",
              "      <td>-0.136067</td>\n",
              "      <td>0.129312</td>\n",
              "      <td>-0.047939</td>\n",
              "      <td>0.026699</td>\n",
              "      <td>-0.096105</td>\n",
              "      <td>-0.023499</td>\n",
              "      <td>0.174090</td>\n",
              "      <td>-0.238289</td>\n",
              "      <td>-0.140972</td>\n",
              "      <td>-0.024266</td>\n",
              "      <td>-0.018695</td>\n",
              "      <td>0.181820</td>\n",
              "      <td>0.034405</td>\n",
              "      <td>-0.071015</td>\n",
              "      <td>-0.025482</td>\n",
              "      <td>0.367904</td>\n",
              "      <td>-0.147210</td>\n",
              "      <td>0.072322</td>\n",
              "      <td>-0.036324</td>\n",
              "      <td>-0.273361</td>\n",
              "      <td>0.011621</td>\n",
              "      <td>0.180177</td>\n",
              "      <td>-0.013121</td>\n",
              "      <td>-0.063572</td>\n",
              "      <td>-0.054614</td>\n",
              "      <td>-0.014609</td>\n",
              "      <td>0.046780</td>\n",
              "      <td>0.104852</td>\n",
              "      <td>0.040055</td>\n",
              "      <td>0.071656</td>\n",
              "      <td>-0.050728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       297       298       299\n",
              "0 -0.002163  0.035122  0.035819  ...  0.080690  0.018476  0.099836\n",
              "1  0.125517  0.040885  0.002634  ...  0.113860  0.037437 -0.029801\n",
              "2  0.027636  0.036000  0.000284  ...  0.152622 -0.059203  0.070782\n",
              "3  0.030151 -0.052437 -0.072858  ...  0.013263 -0.008422  0.044738\n",
              "4  0.093965  0.158807 -0.077798  ...  0.040055  0.071656 -0.050728\n",
              "\n",
              "[5 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "4zL9gJ7iwOwQ",
        "outputId": "a6c66d76-64e0-4fad-eb7f-b18f6e4ce440"
      },
      "source": [
        "###Gettinhg the feature vector of the second question\n",
        "w2v_q2 = averaged_word_vectorizer(corpus=q2, model=model,num_features=300)\n",
        "w2v_q2=pd.DataFrame(w2v_q2)\n",
        "w2v_q2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.006770</td>\n",
              "      <td>0.035375</td>\n",
              "      <td>0.044350</td>\n",
              "      <td>0.057829</td>\n",
              "      <td>-0.115635</td>\n",
              "      <td>-0.171626</td>\n",
              "      <td>0.112717</td>\n",
              "      <td>0.011007</td>\n",
              "      <td>0.029502</td>\n",
              "      <td>-0.122288</td>\n",
              "      <td>-0.074823</td>\n",
              "      <td>-0.010507</td>\n",
              "      <td>0.035184</td>\n",
              "      <td>-0.036754</td>\n",
              "      <td>0.033036</td>\n",
              "      <td>-0.171955</td>\n",
              "      <td>0.164561</td>\n",
              "      <td>-0.066252</td>\n",
              "      <td>-0.001549</td>\n",
              "      <td>-0.029853</td>\n",
              "      <td>-0.273331</td>\n",
              "      <td>-0.110427</td>\n",
              "      <td>0.025161</td>\n",
              "      <td>0.228067</td>\n",
              "      <td>-0.100394</td>\n",
              "      <td>-0.088381</td>\n",
              "      <td>-0.025435</td>\n",
              "      <td>-0.062923</td>\n",
              "      <td>0.074644</td>\n",
              "      <td>-0.155660</td>\n",
              "      <td>-0.141384</td>\n",
              "      <td>-0.072877</td>\n",
              "      <td>-0.179140</td>\n",
              "      <td>0.071767</td>\n",
              "      <td>0.121223</td>\n",
              "      <td>-0.210200</td>\n",
              "      <td>0.188826</td>\n",
              "      <td>0.025963</td>\n",
              "      <td>0.016460</td>\n",
              "      <td>0.126630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138471</td>\n",
              "      <td>0.051584</td>\n",
              "      <td>0.066754</td>\n",
              "      <td>-0.102597</td>\n",
              "      <td>-0.073217</td>\n",
              "      <td>0.041925</td>\n",
              "      <td>-0.040507</td>\n",
              "      <td>0.079605</td>\n",
              "      <td>0.102217</td>\n",
              "      <td>0.017842</td>\n",
              "      <td>-0.015037</td>\n",
              "      <td>0.007262</td>\n",
              "      <td>-0.008160</td>\n",
              "      <td>0.033637</td>\n",
              "      <td>-0.047274</td>\n",
              "      <td>0.176393</td>\n",
              "      <td>-0.048884</td>\n",
              "      <td>-0.026021</td>\n",
              "      <td>0.121512</td>\n",
              "      <td>0.026412</td>\n",
              "      <td>0.025708</td>\n",
              "      <td>0.063131</td>\n",
              "      <td>0.035221</td>\n",
              "      <td>-0.095442</td>\n",
              "      <td>0.122751</td>\n",
              "      <td>0.069848</td>\n",
              "      <td>-0.069591</td>\n",
              "      <td>0.074363</td>\n",
              "      <td>-0.163677</td>\n",
              "      <td>-0.001447</td>\n",
              "      <td>-0.071883</td>\n",
              "      <td>0.090034</td>\n",
              "      <td>-0.059738</td>\n",
              "      <td>0.021351</td>\n",
              "      <td>-0.039727</td>\n",
              "      <td>0.068792</td>\n",
              "      <td>-0.052270</td>\n",
              "      <td>0.099899</td>\n",
              "      <td>-0.013076</td>\n",
              "      <td>0.103618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.025677</td>\n",
              "      <td>0.041063</td>\n",
              "      <td>-0.010478</td>\n",
              "      <td>0.125864</td>\n",
              "      <td>-0.153728</td>\n",
              "      <td>-0.237105</td>\n",
              "      <td>0.138084</td>\n",
              "      <td>0.109157</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>-0.107416</td>\n",
              "      <td>-0.048372</td>\n",
              "      <td>-0.000957</td>\n",
              "      <td>0.004353</td>\n",
              "      <td>-0.046702</td>\n",
              "      <td>-0.073478</td>\n",
              "      <td>-0.166488</td>\n",
              "      <td>-0.038808</td>\n",
              "      <td>-0.014426</td>\n",
              "      <td>0.012046</td>\n",
              "      <td>-0.224775</td>\n",
              "      <td>-0.161864</td>\n",
              "      <td>-0.094914</td>\n",
              "      <td>-0.031436</td>\n",
              "      <td>0.076708</td>\n",
              "      <td>-0.109162</td>\n",
              "      <td>-0.017987</td>\n",
              "      <td>-0.020014</td>\n",
              "      <td>0.014498</td>\n",
              "      <td>0.103899</td>\n",
              "      <td>-0.064647</td>\n",
              "      <td>-0.159054</td>\n",
              "      <td>-0.119929</td>\n",
              "      <td>-0.128476</td>\n",
              "      <td>0.055531</td>\n",
              "      <td>0.138652</td>\n",
              "      <td>-0.195239</td>\n",
              "      <td>0.202705</td>\n",
              "      <td>-0.042660</td>\n",
              "      <td>-0.050869</td>\n",
              "      <td>0.011657</td>\n",
              "      <td>...</td>\n",
              "      <td>0.161259</td>\n",
              "      <td>0.136491</td>\n",
              "      <td>0.045777</td>\n",
              "      <td>0.039886</td>\n",
              "      <td>-0.192229</td>\n",
              "      <td>0.018224</td>\n",
              "      <td>-0.054691</td>\n",
              "      <td>-0.015451</td>\n",
              "      <td>0.091640</td>\n",
              "      <td>-0.028081</td>\n",
              "      <td>0.081818</td>\n",
              "      <td>0.128608</td>\n",
              "      <td>0.043925</td>\n",
              "      <td>0.018105</td>\n",
              "      <td>-0.018391</td>\n",
              "      <td>0.189950</td>\n",
              "      <td>0.030789</td>\n",
              "      <td>-0.045267</td>\n",
              "      <td>0.018710</td>\n",
              "      <td>0.043873</td>\n",
              "      <td>0.050564</td>\n",
              "      <td>-0.054618</td>\n",
              "      <td>-0.044662</td>\n",
              "      <td>-0.136470</td>\n",
              "      <td>0.178675</td>\n",
              "      <td>-0.015606</td>\n",
              "      <td>0.063794</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>-0.223065</td>\n",
              "      <td>0.076823</td>\n",
              "      <td>-0.045094</td>\n",
              "      <td>0.143073</td>\n",
              "      <td>-0.006911</td>\n",
              "      <td>-0.058510</td>\n",
              "      <td>0.038092</td>\n",
              "      <td>0.099946</td>\n",
              "      <td>-0.053367</td>\n",
              "      <td>0.085994</td>\n",
              "      <td>0.113280</td>\n",
              "      <td>-0.021845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.077759</td>\n",
              "      <td>-0.016381</td>\n",
              "      <td>0.077047</td>\n",
              "      <td>0.098422</td>\n",
              "      <td>-0.207392</td>\n",
              "      <td>-0.136691</td>\n",
              "      <td>0.210272</td>\n",
              "      <td>0.026431</td>\n",
              "      <td>-0.056066</td>\n",
              "      <td>0.128840</td>\n",
              "      <td>-0.033147</td>\n",
              "      <td>0.001187</td>\n",
              "      <td>-0.047874</td>\n",
              "      <td>-0.126005</td>\n",
              "      <td>0.217938</td>\n",
              "      <td>-0.150199</td>\n",
              "      <td>0.092783</td>\n",
              "      <td>-0.085469</td>\n",
              "      <td>0.165031</td>\n",
              "      <td>-0.204510</td>\n",
              "      <td>-0.169255</td>\n",
              "      <td>-0.075837</td>\n",
              "      <td>0.166701</td>\n",
              "      <td>0.263945</td>\n",
              "      <td>-0.135471</td>\n",
              "      <td>0.012720</td>\n",
              "      <td>0.006870</td>\n",
              "      <td>0.056879</td>\n",
              "      <td>0.095398</td>\n",
              "      <td>-0.130474</td>\n",
              "      <td>-0.212130</td>\n",
              "      <td>-0.136630</td>\n",
              "      <td>-0.018187</td>\n",
              "      <td>0.071787</td>\n",
              "      <td>0.159427</td>\n",
              "      <td>-0.098913</td>\n",
              "      <td>0.132770</td>\n",
              "      <td>0.122076</td>\n",
              "      <td>0.167503</td>\n",
              "      <td>0.044963</td>\n",
              "      <td>...</td>\n",
              "      <td>0.064910</td>\n",
              "      <td>0.051673</td>\n",
              "      <td>-0.187855</td>\n",
              "      <td>0.046922</td>\n",
              "      <td>-0.076063</td>\n",
              "      <td>-0.054391</td>\n",
              "      <td>-0.079231</td>\n",
              "      <td>-0.023488</td>\n",
              "      <td>-0.051817</td>\n",
              "      <td>-0.121312</td>\n",
              "      <td>0.015360</td>\n",
              "      <td>0.125372</td>\n",
              "      <td>0.056159</td>\n",
              "      <td>-0.036989</td>\n",
              "      <td>0.008194</td>\n",
              "      <td>0.089484</td>\n",
              "      <td>-0.034102</td>\n",
              "      <td>0.065161</td>\n",
              "      <td>0.107047</td>\n",
              "      <td>-0.000585</td>\n",
              "      <td>0.095759</td>\n",
              "      <td>-0.134772</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>-0.124444</td>\n",
              "      <td>0.139608</td>\n",
              "      <td>0.108835</td>\n",
              "      <td>-0.075976</td>\n",
              "      <td>-0.030122</td>\n",
              "      <td>-0.197230</td>\n",
              "      <td>0.001449</td>\n",
              "      <td>-0.110807</td>\n",
              "      <td>-0.018022</td>\n",
              "      <td>-0.047666</td>\n",
              "      <td>0.190168</td>\n",
              "      <td>-0.001577</td>\n",
              "      <td>-0.035675</td>\n",
              "      <td>-0.144106</td>\n",
              "      <td>0.109393</td>\n",
              "      <td>-0.052015</td>\n",
              "      <td>0.087755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.187805</td>\n",
              "      <td>0.145141</td>\n",
              "      <td>-0.122112</td>\n",
              "      <td>-0.057024</td>\n",
              "      <td>-0.174879</td>\n",
              "      <td>-0.341742</td>\n",
              "      <td>-0.006988</td>\n",
              "      <td>0.129127</td>\n",
              "      <td>0.032518</td>\n",
              "      <td>-0.193707</td>\n",
              "      <td>0.009471</td>\n",
              "      <td>-0.002763</td>\n",
              "      <td>-0.129950</td>\n",
              "      <td>-0.212242</td>\n",
              "      <td>0.210302</td>\n",
              "      <td>-0.043794</td>\n",
              "      <td>0.014973</td>\n",
              "      <td>0.032812</td>\n",
              "      <td>0.081041</td>\n",
              "      <td>-0.229818</td>\n",
              "      <td>-0.166019</td>\n",
              "      <td>0.089435</td>\n",
              "      <td>0.064523</td>\n",
              "      <td>0.386981</td>\n",
              "      <td>-0.145883</td>\n",
              "      <td>-0.061587</td>\n",
              "      <td>-0.055765</td>\n",
              "      <td>0.018053</td>\n",
              "      <td>-0.055151</td>\n",
              "      <td>-0.067727</td>\n",
              "      <td>-0.297031</td>\n",
              "      <td>-0.172887</td>\n",
              "      <td>-0.256486</td>\n",
              "      <td>0.113150</td>\n",
              "      <td>0.024793</td>\n",
              "      <td>-0.242646</td>\n",
              "      <td>0.219499</td>\n",
              "      <td>0.089579</td>\n",
              "      <td>0.092485</td>\n",
              "      <td>0.115697</td>\n",
              "      <td>...</td>\n",
              "      <td>0.052821</td>\n",
              "      <td>-0.125429</td>\n",
              "      <td>-0.164286</td>\n",
              "      <td>0.272388</td>\n",
              "      <td>-0.070644</td>\n",
              "      <td>-0.170021</td>\n",
              "      <td>-0.055791</td>\n",
              "      <td>0.131320</td>\n",
              "      <td>0.144192</td>\n",
              "      <td>0.081724</td>\n",
              "      <td>0.092085</td>\n",
              "      <td>-0.138915</td>\n",
              "      <td>0.082932</td>\n",
              "      <td>0.027455</td>\n",
              "      <td>-0.177780</td>\n",
              "      <td>-0.026713</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>-0.071738</td>\n",
              "      <td>0.044241</td>\n",
              "      <td>0.117010</td>\n",
              "      <td>0.021830</td>\n",
              "      <td>-0.030250</td>\n",
              "      <td>-0.030706</td>\n",
              "      <td>-0.293017</td>\n",
              "      <td>0.251517</td>\n",
              "      <td>0.102950</td>\n",
              "      <td>-0.094357</td>\n",
              "      <td>-0.194424</td>\n",
              "      <td>-0.194024</td>\n",
              "      <td>0.013925</td>\n",
              "      <td>-0.024201</td>\n",
              "      <td>-0.069443</td>\n",
              "      <td>-0.089295</td>\n",
              "      <td>-0.058624</td>\n",
              "      <td>0.028572</td>\n",
              "      <td>0.083252</td>\n",
              "      <td>-0.136099</td>\n",
              "      <td>0.092510</td>\n",
              "      <td>0.118084</td>\n",
              "      <td>-0.092567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.099501</td>\n",
              "      <td>0.202996</td>\n",
              "      <td>-0.092809</td>\n",
              "      <td>0.147664</td>\n",
              "      <td>-0.176063</td>\n",
              "      <td>-0.237572</td>\n",
              "      <td>0.075940</td>\n",
              "      <td>0.171197</td>\n",
              "      <td>0.108704</td>\n",
              "      <td>-0.036627</td>\n",
              "      <td>0.098429</td>\n",
              "      <td>0.005307</td>\n",
              "      <td>-0.106001</td>\n",
              "      <td>-0.083511</td>\n",
              "      <td>-0.021120</td>\n",
              "      <td>-0.176958</td>\n",
              "      <td>-0.127362</td>\n",
              "      <td>0.009651</td>\n",
              "      <td>0.165747</td>\n",
              "      <td>-0.137530</td>\n",
              "      <td>-0.182989</td>\n",
              "      <td>-0.092473</td>\n",
              "      <td>0.051795</td>\n",
              "      <td>0.085957</td>\n",
              "      <td>-0.094166</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.018613</td>\n",
              "      <td>0.069603</td>\n",
              "      <td>0.034281</td>\n",
              "      <td>-0.119865</td>\n",
              "      <td>0.103738</td>\n",
              "      <td>-0.027658</td>\n",
              "      <td>0.011223</td>\n",
              "      <td>0.095228</td>\n",
              "      <td>0.129287</td>\n",
              "      <td>-0.066396</td>\n",
              "      <td>0.271292</td>\n",
              "      <td>-0.147394</td>\n",
              "      <td>0.173602</td>\n",
              "      <td>0.064841</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034986</td>\n",
              "      <td>-0.041181</td>\n",
              "      <td>-0.105363</td>\n",
              "      <td>0.106510</td>\n",
              "      <td>-0.216116</td>\n",
              "      <td>0.054549</td>\n",
              "      <td>-0.124350</td>\n",
              "      <td>0.021950</td>\n",
              "      <td>-0.016887</td>\n",
              "      <td>-0.149604</td>\n",
              "      <td>0.056061</td>\n",
              "      <td>0.028158</td>\n",
              "      <td>0.044853</td>\n",
              "      <td>-0.166660</td>\n",
              "      <td>0.124430</td>\n",
              "      <td>0.381972</td>\n",
              "      <td>-0.107089</td>\n",
              "      <td>-0.241160</td>\n",
              "      <td>-0.020549</td>\n",
              "      <td>-0.088574</td>\n",
              "      <td>0.124439</td>\n",
              "      <td>0.042976</td>\n",
              "      <td>-0.046354</td>\n",
              "      <td>0.015025</td>\n",
              "      <td>0.403595</td>\n",
              "      <td>-0.074358</td>\n",
              "      <td>0.185899</td>\n",
              "      <td>0.051971</td>\n",
              "      <td>-0.248449</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.164916</td>\n",
              "      <td>0.045743</td>\n",
              "      <td>-0.069067</td>\n",
              "      <td>-0.131181</td>\n",
              "      <td>-0.027192</td>\n",
              "      <td>0.125652</td>\n",
              "      <td>0.104837</td>\n",
              "      <td>0.027878</td>\n",
              "      <td>0.159654</td>\n",
              "      <td>0.021481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       297       298       299\n",
              "0 -0.006770  0.035375  0.044350  ...  0.099899 -0.013076  0.103618\n",
              "1  0.025677  0.041063 -0.010478  ...  0.085994  0.113280 -0.021845\n",
              "2  0.077759 -0.016381  0.077047  ...  0.109393 -0.052015  0.087755\n",
              "3  0.187805  0.145141 -0.122112  ...  0.092510  0.118084 -0.092567\n",
              "4  0.099501  0.202996 -0.092809  ...  0.027878  0.159654  0.021481\n",
              "\n",
              "[5 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoxNQiNRxElE"
      },
      "source": [
        "##Getting absolute difference between the two questions \n",
        "x=abs(w2v_q1-w2v_q2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeQ_xngkTrzS",
        "outputId": "4a724c9f-c4fe-4198-bca6-9dabc9db0ec2"
      },
      "source": [
        "np.array(w2v_q2).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404199, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz2YqKW38Bct"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eza2f2-QElBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24341df-edbd-4a48-ceec-2b874cad5e71"
      },
      "source": [
        "print('Decision Tree on word2vec')\n",
        "estimators(x[:200000], train_df.is_duplicate.values[:200000], 'DecisionTree')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree on word2vec\n",
            "Decision Tree  Train Accuracy :  64.42999999999999\n",
            "Decision Tree  Test Accuracy :  62.395\n",
            "\n",
            "\t\tTEST DATA METRICS\n",
            "Decision Tree  Confusion Matrix:  [[17038  8029]\n",
            " [ 7013  7920]]\n",
            "Decision Tree  Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.68      0.69     25067\n",
            "           1       0.50      0.53      0.51     14933\n",
            "\n",
            "    accuracy                           0.62     40000\n",
            "   macro avg       0.60      0.61      0.60     40000\n",
            "weighted avg       0.63      0.62      0.63     40000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I91MLo3O1TMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a85d8f5-9ad3-4432-ae90-f06a36bf5f1e"
      },
      "source": [
        "print('Random Forest on word2vec')\n",
        "estimators(x[:200000], train_df.is_duplicate.values[:200000], 'RandomForest')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest on word2vec\n",
            "RandomForest  Train Accuracy :  81.49187500000001\n",
            "RandomForest  Test Accuracy :  66.8725\n",
            "\n",
            "\t\tTEST DATA METRICS\n",
            "RandomForest  Confusion Matrix:  [[21551  3516]\n",
            " [ 9735  5198]]\n",
            "RandomForest  Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.86      0.76     25067\n",
            "           1       0.60      0.35      0.44     14933\n",
            "\n",
            "    accuracy                           0.67     40000\n",
            "   macro avg       0.64      0.60      0.60     40000\n",
            "weighted avg       0.65      0.67      0.64     40000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}